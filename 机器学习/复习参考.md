### 一、引言

- 数据中的知识发现包括哪几个步骤？

  数据库中知识发现（knowledge discovery in database, KDD），KDD是将未加工的数据转换为又用信息的整个过程。

  输入数据->数据预处理->数据挖掘->后处理->信息

- 数据挖掘应用

  - 聚类分析
  - 预测建模
  - 关联分析
  - 异常检测

### 二、学习的可行性

- Hoeffding 不等式

  

- 用 Hoeffding 不等式说明学习的可行性





### 三、数据和数据预处理

- **有哪四种不同的属性类型？分别可以进行什么操作？（p17）**

  - 标称（nominal）

    众数、熵、列联相关、 $\chi^2$ 检验

  - 序数（ordinal）

    中值、百分位、秩相关、游程检验、符号检验

  - 区间（interval）

    均值、标准差、皮尔逊相关、t和F检验

  - 比率（ratio）

    几何平均、调和平均、百分比变差

- **非对称属性？（p18）**

  对于非对称属性（asymmetric attribute），出现非零属性值才是重要的。

  只有非零值才重要的二元属性是非对称的二元属性。

- **数据对象之间相似度、相异度计算（p41-p42）**

  - 相异度

    - 欧氏距离
    - 曼哈顿距离
    - 马氏距离（p48）

    距离的性质：非负性、对称性、三角不等式。

  - 相似度

    - 二元数据相似度度量（p43）：算0-0和不算0-0（Jaccard）

    - 余弦相似度

    - 广义 Jaccard 系数（Tanimoto系数）

      广义 Jaccard 系数可以用于文档数据，并在二元属性情况下规约为Jaccard系数。用 $EJ$ 表示。
      $$
      EJ(x,y) = \frac{x \cdot y}{\Vert x\Vert^2 + \Vert y\Vert^2 - x \cdot y}
      $$
      

    - 相关性（Correlation）（p46）
    - 组合异种属性的相似度（p49）

- **数据预处理的主要任务**

  ~~聚集、抽样、维归约、特征子集选择、特征创建、离散化和二元化、变量变换~~

  数据清理、聚集、转换、缩减、离散化

- **处理缺失值的方法？**（ppt 37）

  - 缩减数据集，淘汰所有缺失值的样本

  - 填补缺失值

    专家给出填补意见，或者用常数填补：一个数、特征平均、最可能的值（其他样本中该属性的值）。

### 四. 决策树学习

- **决策树学习的基本思想**

  决策树是运用于分类的一种树结构，其中的每个内部节点代表对某一属性的一次测试，每条边代表一个测试结果，叶节点代表某个类或类的分布。决策树的决策过程需要从决策树的根节点开始，待测数据与决策树中的特征节点进行比较，并按照比较结果选择选择下一比较分支，直到叶子节点作为最终的决策结果

- **分类错误率，熵，信息增益的概念，如何根据不同度量选择最佳划分（p97）**

  - 信息增益的概念（p98）

  - 三种度量：熵、Gini、分类误差（p97）

    度量值越小越好。（例p99 图 4-14）

- **缺失值对决策树有何影响？（ppt 60）**

  - 影响不纯度度量的计算
  - 如何把有缺失值的样本分配给子结点
  - 一个有缺失值的测试样本如何分类

- **给定混淆矩阵，分类效果度量不同指标的含义及计算方法。（p91）**

  - 错误率
  - 准确率

- **评估分类器性能的留一法和 k 折交叉验证（p115）**

  留一是留一个验证集。

- **过拟合和欠拟合**

  - 过拟合：树的规模变得太大，训练误差还在降低，检验误差开始增大
  - 欠拟合：树的规模很小，训练和检验误差都很大。

### 五．神经网络

- 神经网络如何学习？ 有何特点？（ppt 6）

  - 给网络的节点随机初始化权重，输入样本，最小化损失函数的值，通过梯度的反向传播，更新网络参数，迭代多次。在测试阶段，给没见过的数据分类。
  - 需要很长时间训练、对不完整和有噪声的数据容忍度很高

- 梯度下降算法

  可以写线性回归的例子。

- 多层神经网络使用什么算法进行训练？（ppt 29）

  一个隐层的MLP，正向传播（sigmod(f(x))），反向传播更新梯度。

### 六．贝叶斯学习

- 根据贝叶斯理论，如何计算一个假设 h 成立的后验概率？