

## Sampler采样函数基类

```python
torch.utils.data.Sampler(data_source)
```

- 所有的采样器必须继承此类
- 子类重写`__iter__()`方法，提供一种遍历 dataset 元素索引的方法
- 重写`__len__()`方法，返回数据集长度
- pytorch 中提供的采样方法有 `SequentialSampler`, `RandomSampler`, `SubsetRandomSampler`, `WeightedRandomSampler`

## SequentialSampler顺序取样

- 源码

  ```python
  class SequentialSampler(Sampler[int]):
      r"""Samples elements sequentially, always in the same order.
  
      Args:
          data_source (Dataset): dataset to sample from
      """
      data_source: Sized
  
      def __init__(self, data_source: Sized) -> None:
          self.data_source = data_source
  
      def __iter__(self) -> Iterator[int]:
          return iter(range(len(self.data_source)))
  
      def __len__(self) -> int:
          return len(self.data_source)
  
  ```

```python
# 顺序取样
torch.utils.data.SequentialSampler(data_source)
# __iter__()
iter(range(len(self.data_source)))
# usage
for i in SequentialSampler(t):
    print(i,end=',')
```



## RandomSampler随机取样

```python
# replacement: 是否又放回的取样
# num_samples: 每次抽样的数量
torch.utils.data.RandomSampler(data_source, replacement=False, num_samples=None)
# __iter__()
n = len(self.data_source)
if self.replacement:
    return iter(torch.randint(high=n, 
                              size=(self.num_samples,),
                              dtype=torch.int64).tolist())
return iter(torch.randperm(n).tolist())
```

## SubsetRandomSampler索引随机采样

```python
# 对数组随机排序后，根据索引取样
torch.utils.data.SubsetRandomSampler(indices)
# __iter__()
(self.indices[i] for i in torch.randperm(len(self.indices)))
```

## WeightedRandomSampler加权随机采样

```python
# 
torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True)
# __iter__()
iter(torch.multinomial(self.weights, self.num_samples, self.replacement).tolist())
```

1. 参数
  - `weights`为index权重，权重越大的取到的概率越高
  - `multinomial()`： 伯努利随机数生成函数，也就是根据概率设定生成{0,1，…,n}

2. 示例

   ```python
   list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True))
   # oupput [4, 4, 1, 4, 5]
   list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False))
   # oupput [0, 1, 4, 3, 2]
   ```

## BatchSampler批采样

```python
# 
torch.utils.data.BatchSampler(sampler, batch_size, drop_last)
# __iter__()
batch = []
for idx in self.sampler:
    batch.append(idx)
    if len(batch) == self.batch_size:
        yield batch
        batch = []
if len(batch) > 0 and not self.drop_last:
    yield batch
```

1. 示例

   ```python
   list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))
   # [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
   list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))
   # [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
   
   ```

   