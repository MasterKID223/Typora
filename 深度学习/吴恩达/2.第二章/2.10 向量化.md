

## 作用

```tex
1. 目的是为了加快计算
2. 对于logistic回归，z = transpose(w)*x + b, 使用两层for循环计算向量w和x的内积很慢，使用特定的向量计算函数会加速计算
3. 尽量使用torch或者numpy中的内置函数
```

`使用向量化优化logistic梯度下降`

> ![image-20220914203926515](F:\Typora\深度学习\吴恩达\第二章\2.10 向量化.assets\image-20220914203926515.png)
>
> ![image-20220914204629738](F:\Typora\深度学习\吴恩达\第二章\2.10 向量化.assets\image-20220914204629738.png)
>
> ```tex
> 1. 这里A是整个训练集的预测值
> ```

`把梯度下降过程中的所有for循环去掉`

```tex
1. 和去掉第一个for循环的方法一样，把z(i) 和 a(i) 变成向量，然后调用numpy的库函数计算
```

> ![image-20220914215924828](F:\Typora\深度学习\吴恩达\第二章\2.10 向量化.assets\image-20220914215924828.png)

