### 2.1 Mini-batch梯度下降

一般的梯度下降要遍历完整个训练集之后才执行一次剃度下降，把train set划分成batch之后，每个batch执行一次网络梯度的更新。

![image-20230102164122467](./pic/image-20230102164122467.png)

### 2.6 Momentum梯度下降法

原理：计算梯度的指数加权平均数，并利用该梯度更新你的权重。

它解决的是，在梯度下降过程中的振荡问题，使用这个算法可以让梯度下降的更快。

![image-20230102164658090](./pic/image-20230102164658090.png)

![image-20230102172146523](./pic/image-20230102172146523.png)