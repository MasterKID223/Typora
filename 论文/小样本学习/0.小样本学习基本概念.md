

## 基本概念

`meta learning`

> <img src="pic\image-20220912192739083.png" alt="image-20220912192739083" style="zoom:50%;" />
>
> ```tex
> 1. 目的是为了让模型有自主学习的能力
> 2. support 提供一个给小朋友学习的参考
> ```
>
> <img src="pic\image-20220912192850774.png" alt="image-20220912192850774" style="zoom:80%;" />



`Supervised Learning vs. Few-Shot Learning`

> <img src="pic\image-20220912193048978.png" alt="image-20220912193048978" style="zoom:50%;" />
>
> ```tex
> 1.  传统的监督学习训练集中没有的类，测试分类会失败
> 2. 小样本学习，比较query 和 support set 里样本的相似度判断是不是该类
> 3. support set 不在训练集里
> ```
>
> <img src="pic\image-20220912193302427.png" alt="image-20220912193302427" style="zoom:50%;" />

`k-way n-shot`

> <img src="pic\image-20220912193426632.png" alt="image-20220912193426632" style="zoom:50%;" />
>
> <img src="pic\image-20220912193452357.png" alt="image-20220912193452357" style="zoom:50%;" />

`分类准确率`

> ```tex
> 1. 类别越少分类准确率越高
> ```
>
> <img src="pic\image-20220912193628662.png" alt="image-20220912193628662" style="zoom:50%;" />
>
> ```tex
> 1. 每个类里的样本越多，分类准确率越高
> ```
>
> <img src="pic\image-20220912193736970.png" alt="image-20220912193736970" style="zoom:50%;" />



## Omniglot数据集

```tex
1. 手写的语言字符
2. 160多个类，每个类20个字符（样本）
3. 50个字母表
```

> ![image-20220912194315898](F:\Typora\论文\0.小样本学习基本概念.assets\image-20220912194315898.png)

## Mini-ImageNet数据集

```tex
1. 100个类，每个类600个样本（84*84）
```

> <img src="pic/image-20220912194525816.png" alt="image-20220912194525816" style="zoom:50%;" />



## 孪生网络(Siamese Network)

```tex
1. 通过神经网络提取特征，再把特征进行比对，经过sigmoid函数，与target作比较，得出loss反过来更新网络
```

> <img src="pic\image-20220912203228848.png" alt="image-20220912203228848" style="zoom:50%;" />
>
> <img src="pic\image-20220912203245983.png" alt="image-20220912203245983" style="zoom:50%;" />



## 小样本学习的基本思路

```tex
1. 计算query 与 support set 里每一个类的距离，根据 dist 的大小判断query的类别
2. support set 的类不属于训练集
```

> <img src="pic\image-20220912210328201.png" alt="image-20220912210328201" style="zoom:50%;" />

## Triplet Loss

```tex
1. 在训练的过程中，选取一个样本（anchor），再选取同一类的X+，不同类的X-
2. 计算d+，d-，即与正样本和负样本之间距离
```

> <img src="pic\image-20220912210504864.png" alt="image-20220912210504864" style="zoom:50%;" />
>
> <img src="pic\image-20220912210728737.png" alt="image-20220912210728737" style="zoom:50%;" />

## Pretaining + Fine Tuning 

`Cosine Similarity`

```
余弦相似度，一个向量在另一个向量上的投影
```

> # <img src="pic\image-20220912223142135.png" alt="image-20220912223142135" style="zoom:50%;" />
>
> <img src="pic\image-20220912223215896.png" alt="image-20220912223215896" style="zoom:50%;" />

`softmax函数`

```tex
1. 输出一个概率分布，大的元素变大，小的元素变小
```

`Pretaining`

```tex
1. 小样本学习使用大数据训练好的预训练模型，来提取特征向量
```

`mean vector`

> ```tex
> 1. mean vector表示一个类特征
> 2. 通过比较μ和query来确定类别
> ```
>
> <img src="pic\image-20220912223834151.png" alt="image-20220912223834151" style="zoom:50%;" />

`Few-shot Prediction`

```

```

> <img src="pic\image-20220912224402174.png" alt="image-20220912224402174" style="zoom:50%;" />
>
> <img src="pic\image-20220912224434163.png" alt="image-20220912224434163" style="zoom:50%;" />

## Fine Tuning 

> <img src="pic\image-20220912234012749.png" alt="image-20220912234012749" style="zoom:50%;" />
>
> 

`技巧一`

> ```tex
> 初始化技巧
> ```
>
> <img src="pic\image-20220912234041973.png" alt="image-20220912234041973" style="zoom:50%;" />

`技巧2`

```
使用regularization防止过拟合
```

>  <img src="pic\image-20220912234129083.png" alt="image-20220912234129083" style="zoom:50%;" />
>
> <img src="pic\image-20220912234257185.png" alt="image-20220912234257185" style="zoom:50%;" />

`技巧3`

> ```tex
> 1. 把softmax里的wq换成余弦相似度，可以大幅提高预测准确率
> ```
>
> <img src="pic\image-20220912235017131.png" alt="image-20220912235017131" style="zoom:50%;" />
