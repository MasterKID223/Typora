## BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning
Representation Learning

作者：Zhi Hou（悉尼大学）

来源：CVPR 2022

论文：[[thecvf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_BatchFormer_Learning_To_Explore_Sample_Relationships_for_Robust_Representation_Learning_CVPR_2022_paper.pdf)]

代码：[[github](https://github.com/zhihou7/BatchFormer)]

引用数：9



### 创新点

学习每个mini-batch里样本之间的关系。

为了缩小训练和测试的差距，共享了classifer的参数，所以BatchFormer在测试的时候可以去掉。

在长尾识别问题，Compositional Zero-Shot Recognition，domain generalization，contrastive learning上都做了实验。

不同类间特征迁移，相同类间学习不变性。

<img src="./pic/image-20230115172219315.png" alt="image-20230115172219315" style="zoom:25%;" />

### 3.方法

#### 3.1 概述

<img src="./pic/image-20230115172530057.png" alt="image-20230115172530057" style="zoom:33%;" />

1. 首先在每个mini-batch内提取每个样本的特征，这个过程没有cat操作。
2. 接一个Transformer（里面是交叉注意力机制），并把这个模块叫BatchFormer。
3. BatchFormer出来的cls_token（或者是patches）送进classifier分类。
4. 两个classifier共享权重。

![image-20230115173111831](./pic/image-20230115173111831.png)

#### 3.2. BatchFormer

**Transformer Encoder.** 多头注意力（MSA）+MLP+LayerNorm（LN）。$X \in R^{N \times C}$，表示输入encoder的特征，$N$是batch大小，$C$是特征维度，$l$是encoder的第几层。那么，encoder的输出是：

![image-20230115173638067](./pic/image-20230115173638067.png)

用多头注意力学习一个batch里的关系。BatchFormer和一般的Transformer的输入不一样，BatchFormer首先要把输入reshape一下，transformer才能作用在batch维度上。

**Shared Classifier.** 一个辅助的分类器，和最后的分类器共享权重，这样不仅学到了最后的分类结果，还学到了特征的不变性。在测试阶段可以把BatchFormer模块去掉。

BatchFormer是一个学习鲁棒性表征可拔插的模块。在训练阶段，BatchFormer可以和backbone（特征提取，CNNs和Vit）用端到端的方式一起训练。

#### 3.3. BatchFormer: A Gradient View

数学上的解释。





### 10. 代码分析

```python
def BatchFormer(x, y, encoder, is_training):
    # x: input features with the shape [N, C]
    # encoder: TransformerEncoderLayer(C,4,C,0.5) (特征输入维度，头数，MLP输出维度，dropout)
    if not is_training:
        return x, y
    pre_x = x
    x = encoder(x.unsqueeze(1)).squeeze(1)
    x = torch.cat([pre_x, x], dim=0)
    y = torch.cat([y, y], dim=0)
    return x, y
```

