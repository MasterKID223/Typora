# 小样本学习原型网络（prototypical net）



## 摘要

```tex
1. protonet 根据很少的样本生成训练集中没有的新类
2. protonet 学习一个 metric space ， 通过计算每个类到 proto 的距离分类
```



## Prototypical Networks

1. `Notation`

   > ![image-20220813020316710](F:\Typora\论文\Prototypical Networks for Few-shot Learning.assets\image-20220813020316710.png)
   
   ```json
   {
   	N: "n分类",
       S: "样本集合",
       Xi: "d维向量",
       Yi: "x的类别",
       Sk: "分类为k的集合"
   }
   ```
   
   > ![image-20220815161226283](F:\Typora\论文\1.Prototypical Networks for Few-shot Learning.assets\image-20220815161226283.png)
   >
   > ```tex
   > 1. zero-shot的向量 v : ck = g(vk), vk = {1, ..., K}
   > ```
   >
   > 
   
2.  `Model`

   > ![image-20220813110920693](F:\Typora\论文\1.Prototypical Networks for Few-shot Learning.assets\image-20220813110920693.png)
   >
   > ```tex
   > 1. 网络的输入是 m维向量 ck， 或者是一个 prototype 类型的向量（D -> M 嵌入空间的均值向量）
   > ```
   >
   > ![image-20220813161624306](F:\Typora\论文\1.Prototypical Networks for Few-shot Learning.assets\image-20220813161624306.png)
   >
   > ```tex
   > 1. 给定 m维上 embedding space 的距离函数 d
   > 2. protonet 生成点x的类分布情况，根据到 prototype 距离的softmax
   > ```
   >
   > ![image-20220813162151741](F:\Typora\论文\1.Prototypical Networks for Few-shot Learning.assets\image-20220813162151741.png)
   >
   > 
   >
   > ```tex
   > # 学习过程
   > 1. 用SGD最小化J(Ф)，损失函数
   > 2. 通过从训练集中随机选择一个类子集，然后选择每个类中的一个子集作为支持集，并选择剩余部分的子集作为查询点，形成训练集
   > ```

3. `计算损失J(Ф)的算法`

   > ![image-20220813163647189](F:\Typora\论文\1.Prototypical Networks for Few-shot Learning.assets\image-20220813163647189.png)
   >
   > ```json
   > // 参数
   > {
   > 	N: "训练集大小",
   >     K: "训练集有多少class",
   >     Nc: "训练每次迭代的数量",
   >     Ns: "每个support class的大小",
   >     NQ: "每个query class的大小",
   >     RandomSample(S, N): "随机的在集合S中选N个元素"
   > }
   > ```
   >
   > ![image-20220813164358250](F:\Typora\论文\1.Prototypical Networks for Few-shot Learning.assets\image-20220813164358250.png)

4. `Prototypical Networks as Mixture Density Estimation`

   - [笔记1](https://zhuanlan.zhihu.com/p/410289164)

   - [如何理解Bregman divergence](https://www.zhihu.com/question/22426561/answer/209945856)

5. `Reinterpretation as a Linear Model`

   > ![image-20220813172632470](F:\Typora\论文\1.Prototypical Networks for Few-shot Learning.assets\image-20220813172632470.png)
   >
   > ```tex
   > 作者使用欧式距离将原型网络在embedding 空间上的分类解释成了一个线性函数，同时他认为所有的非线性计算都在f(Ф) 中进行，且认为使用欧式距离使得方法更加简单有效。
   > ```

6. `Design Choices`

   - `Episode composition`

     ```tex
     we found that it is usually best to train and test with the same “shot” number.
     ```
