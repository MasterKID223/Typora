### 0. 对比损失表格



### 1. SimCLR中的损失

论文：[[arxiv](https://arxiv.org/pdf/1807.03748)]

代码：[[github](https://github.com/sthalles/SimCLR/blob/master/simclr.py)]

#### 损失公式

SimCLR论文中给出的公式：

<img src="./pic/image-20221216174445001.png" alt="image-20221216174445001" style="zoom: 80%;" />

Supervised contrastive learning 论文中给出的公式：

<img src="./pic/image-20221216203517204.png" alt="image-20221216203517204" style="zoom:80%;" />

#### 代码实现

数据集：[[斯坦福大学stl10](https://cs.stanford.edu/~acoates/stl10/)]，10个类，96x96的彩色图像，每个类500训练图片，800测试图片。

- 前提的参数

  | 参数       | 值   | 备注                                         |
  | ---------- | ---- | -------------------------------------------- |
  | batch_size | 256  |                                              |
  | n_views    | 2    | 对256个样本作论文中提到的数据扩增，256*2=512 |
  | temperture | 0.07 | 损失公式中的 $\tau$                          |
  | out_dim    | 128  | 从embedding网络中出来的维度：(512,128)       |

  

```python
def info_nce_loss(self, features):  # (512,128)
	# [0, 1, ..., 255, 0, 1, ..., 255]
    labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)   # (512,)
    # 对角线全是1，单位矩阵
    '''
    [0, 1, 0, 1] == [0, 1, 0, 1].T
    1 0 1 0
    0 1 0 1
    1 0 1 0
    0 1 0 1
    '''
    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()   # (512,512)   
    labels = labels.to(self.args.device)

    features = F.normalize(features, dim=1) # (512, 128)  # 送入对比损失之前要归一化
	# 归一化之后做点积相当于是余弦相似度，
    # 特征之间两两做矩阵乘法，对角线上是自己和自己的相似度
    similarity_matrix = torch.matmul(features, features.T)  # (512,512)

    # discard the main diagonal from both: labels and similarities matrix
    # 从标签和相似度矩阵中删除主对角线(自己x自己)，即对角线是False
    mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)    # (512,512)
    '''
    o o o	x o o	o o
    o o o	o x o	o o
    o o o	o o x	o o
    '''
    labels = labels[~mask].view(labels.shape[0], -1)    # (512,511)    # 把除了自己的样本标签留下
    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)   # (512,511)

    # select and combine multiple positives
    # 选择并组合多个正样本
    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)  # (512,1)

    # select only the negatives
    # 只选择负样本
    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)  # (512,510)

    logits = torch.cat([positives, negatives], dim=1)   # (512,511)   # infoNCE的分母
    # 正样本都在第0个位置
    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)    # (512,)

    logits = logits / self.args.temperature # (512,511)
    return logits, labels   # (512,)
    
# 计算损失
logits, labels = info_nce_loss(features)
criterion = torch.nn.CrossEntropyLoss()
loss = criterion(logits, labels)
```



### 2. 监督对比损失

论文：[[neurips](https://proceedings.neurips.cc/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf)]

代码：[[github](https://github.com/HobbitLong/SupContrast)]

#### 损失公式

论文中给出了两个形式的损失（一个在log外，一个在里边）：

<img src="./pic/image-20221216205804743.png" alt="image-20221216205804743" style="zoom: 33%;" />

论文中，在这两个公式下面详细的介绍了这两个损失的区别。并说明了在计算对比损失之前，对特征进行归一化的必要性。

<img src="./pic/image-20221216211519309.png" alt="image-20221216211519309" style="zoom:33%;" />

在经过一系列的数学证明之后，作者的出结论：使用 $\mathcal{L}^{sup}_{out}$ 。

#### 监督对比损失和Triple Loss，N-pairs Loss的联系

> In the Supplementary, we show that the triplet loss is a special case of the contrastive loss when one positive and one negative are used. When more than one negative is used, we show that the SupCon loss becomes equivalent to the N-pairs loss.

- 三元损失是对比损失的一种特殊情况，当只使用一个正样本和一个负样本时。
- 负样本大于一个时，SupCon Loss就等于N-pairs损失。

#### 代码实现：

这个代码可以实现SimCLR的同源图像的InfoNCE损失，和监督损失的同类图像的InfoNCE损失，要求输入的特征经过l2归一化，如果再输入labels，那么计算的就是监督损失，不输入labels就是SimCLR的损失（因为SimCLR默认第一列是正样本对）。

- 前提参数

  | 参数 | 值   | 备注 |
  | ---- | ---- | ---- |
  |      |      |      |
  |      |      |      |
  |      |      |      |

  

```python

```

