## 消息队列

### 消息队列的作用

异步、削峰/限流、解耦。

### 分布式事务



## kafka

kafka是producer + mq(broker + partition) + consumer

kafka的消息格式：Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。

### spring kafka 示例

参考：[[spring官方](https://github.com/spring-projects/spring-kafka/tree/main/samples/sample-01)]

`配置文件`

```yaml
spring:
  kafka:
    producer:
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumer:
      value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
```

`Controller.java`

```java
@RestController
public class Controller {

	@Autowired
	private KafkaTemplate<Object, Object> template;

	@PostMapping(path = "/send/foo/{what}")
	public void sendFoo(@PathVariable String what) {
		this.template.send("topic1", new Foo1(what));
	}
}
```

`Application.java`

```java
@SpringBootApplication
public class Application {

	private final Logger logger = LoggerFactory.getLogger(Application.class);

	private final TaskExecutor exec = new SimpleAsyncTaskExecutor();

	public static void main(String[] args) {
		SpringApplication.run(Application.class, args).close();
	}

	/*
	 * Boot will autowire this into the container factory.
	 */
	@Bean
	public CommonErrorHandler errorHandler(KafkaOperations<Object, Object> template) {
		return new DefaultErrorHandler(
				new DeadLetterPublishingRecoverer(template), new FixedBackOff(1000L, 2));
	}

	@Bean
	public RecordMessageConverter converter() {
		return new JsonMessageConverter();
	}

	@KafkaListener(id = "fooGroup", topics = "topic1")
	public void listen(Foo2 foo) {
		logger.info("Received: " + foo);
		if (foo.getFoo().startsWith("fail")) {
			throw new RuntimeException("failed");
		}
		this.exec.execute(() -> System.out.println("Hit Enter to terminate..."));
	}

	@KafkaListener(id = "dltGroup", topics = "topic1.DLT")
	public void dltListen(byte[] in) {
		logger.info("Received from DLT: " + new String(in));
		this.exec.execute(() -> System.out.println("Hit Enter to terminate..."));
	}

	@Bean
	public NewTopic topic() {
		return new NewTopic("topic1", 1, (short) 1);
	}

	@Bean
	public NewTopic dlt() {  // 死信主题（dead letter topic）
		return new NewTopic("topic1.DLT", 1, (short) 1);
	}

	@Bean
	@Profile("default") // Don't run from test(s)
	public ApplicationRunner runner() {
		return args -> {
			System.out.println("Hit Enter to terminate...");
			System.in.read();
		};
	}

}
```

### chatgpt给出的示例

Apache Kafka是一个分布式流处理平台，它允许你发布和订阅数据流的记录，就像消息队列或企业消息系统一样。使用Kafka，你可以构建强大的数据处理管道，这些管道能够处理来自多个源的高吞吐量数据。下面是一个简单的示例，展示了如何在Java中使用Kafka进行消息的生产和消费。

#### Kafka生产者示例

首先，我们创建一个简单的Kafka生产者，它会发送消息到Kafka集群中的指定主题。

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        String topicName = "testTopic";
        Properties props = new Properties();

        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        Producer<String, String> producer = new KafkaProducer<>(props);
        for(int i = 0; i < 10; i++) {
            producer.send(new ProducerRecord<>(topicName, Integer.toString(i), "Message " + i));
        }
        System.out.println("Message sent successfully");
        producer.close();
    }
}
```

#### Kafka消费者示例

接下来，我们创建一个简单的Kafka消费者，它订阅上面提到的主题，并消费消息。

```java
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        String topicName = "testTopic";
        Properties props = new Properties();

        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "testGroup");
        props.put("enable.auto.commit", "true");
        props.put("auto.commit.interval.ms", "1000");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        Consumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Arrays.asList(topicName));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            records.forEach(record -> {
                System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
            });
        }
    }
}
```

#### 注意事项

- 在运行这些示例之前，请确保你已经安装了Kafka并且Kafka服务器正在运行。
- 需要将`localhost:9092`替换为你的Kafka服务器地址。
- `testTopic`是Kafka中的一个主题，需要提前创建或者配置Kafka允许自动创建主题。
- 这些示例使用的是Kafka的默认序列化器和反序列化器，对于生产环境中更复杂的应用场景，你可能需要使用自定义的序列化器和反序列化器。

这些代码提供了Kafka生产者和消费者的基本框架，你可以根据具体需求对它们进行修改和扩展。

### Kafka 如何保证消息的消费顺序？

使用offset机制。消息从生产端发送到消息队列(Partition)的时候，会分配一个offset，这个offset保证生产端->消息队列的顺序性。

Apache Kafka 保证消息的消费顺序主要通过以下机制和设计原则实现：

#### 1. 分区（Partitions）

- Kafka的主题（Topics）被分割成多个分区（Partitions），每个分区在物理上对应一个有序的、不可变的消息日志。
- 分区允许消息以并行的方式进行处理，每个分区可以独立于其他分区在不同的消费者上进行消费。
- **关键点**：Kafka 只保证在单个分区内的消息是有序的。这意味着，如果一个主题被分成了多个分区，Kafka不能保证跨分区的消息顺序，但是能保证同一分区内消息的顺序。

#### 2. 生产者指定分区

- 当生产者发送消息到主题时，它可以指定一个分区键（Partition Key）。Kafka使用这个键通过哈希函数来分配消息到特定的分区。
- 拥有相同分区键的消息将会被发送到相同的分区，这也意味着这些消息将会按照它们被发送的顺序来被消费。

#### 3. 消费者和消费者组

- 在Kafka中，消费者可以组成一个消费者组（Consumer Group）来订阅一个主题。每个消费者组内，每个分区只会被分配给组内的一个消费者来消费，从而保证了该分区内消息的顺序消费。
- 如果确保一个主题的所有消息都被一个消费者组内的同一个消费者处理，那么这个主题的消息顺序可以被保证。

#### 4. 单分区消费

- 要保证全局的消息顺序，可以使用只有一个分区的主题，或者确保所有消息都发送到同一个分区。
- 这种方法会限制并发处理的能力，因为所有的消息都需要顺序地被单个消费者处理，但它可以保证消息的全局顺序。

#### 5. 顺序保证的限制

- 在分布式系统中，完全的全局顺序保证是有成本的，通常会牺牲一些并行处理能力。因此，设计时需要在消息顺序的严格要求和系统的吞吐量、延迟之间做出平衡。
- 在大多数场景下，基于分区的顺序足够满足需求，因为相关的业务逻辑通常可以通过选择合适的分区键来设计，以确保相关消息在同一分区内顺序处理。

总的来说，Kafka通过分区、合理的消息分配策略和消费者设计，提供了灵活的顺序保证机制，允许开发者根据具体的业务需求和系统设计来平衡消息顺序保证和系统性能。

### Kafka 如何保证消息不丢失？

Kafka为了保证消息不丢失，提供了多种配置和设计特性。通过合理配置这些特性，可以最大程度地保证消息在生产、存储和消费过程中的安全性。以下是确保消息不丢失的主要方法：

#### 1. 生产者确认机制（Producer Acknowledgment）

- Kafka允许生产者在发送消息时选择三种确认模式之一：
  - `acks=0`：生产者不等待来自服务器的任何确认。这种模式下消息丢失的风险最高，但吞吐量也最高。
  - `acks=1`（默认）：生产者等待领导者副本（Leader Replica）收到数据后的确认。这提供了中等级别的数据安全性。
  - `acks=all`或`acks=-1`：生产者等待所有同步副本（Follower Replicas）确认收到数据。这种模式提供了最高级别的数据安全性，但可能影响吞吐量。

#### 2. 数据复制（Replication）

- Kafka的主题可以被配置为跨多个副本（Replicas）进行复制，这些副本分布在不同的服务器上。这意味着即使某些服务器失败，消息数据也能从其他副本中恢复。
- 通过增加副本因子（Replication Factor），可以提高数据的可靠性。副本因子应至少设置为2，更高的副本因子（如3）会提供更好的容错能力。

#### 3. 持久化

- Kafka默认将所有消息持久化到磁盘，这意味着即使服务重启，消息也不会丢失。磁盘故障是唯一可能导致持久化消息丢失的情况，但可以通过在多个磁盘和服务器上复制数据来降低这种风险。

#### 4. 最小同步副本（Min In-Sync Replicas）

- 可以配置`min.insync.replicas`参数来指定在认为消息是提交的之前，必须有多少个副本已经同步了这个消息。如果同步的副本数少于这个值，生产者的发送将会失败。
- 这个参数与`acks=all`配合使用时，可以防止数据丢失。

#### 5. 消费者偏移量的提交（Consumer Offset Commit）

- 消费者读取消息后，会定期提交读取的最新偏移量（Offset）。这确保了即使消费者失败，它也能从最后提交的偏移量重新开始消费，从而避免消息丢失。
- 消费者可以配置为自动提交偏移量或手动提交偏移量。为了保证不丢失消息，建议在消息被成功处理后手动提交偏移量。

#### 6. 适当的日志清理策略

- Kafka允许配置日志的保留策略，例如基于时间或日志大小。合理配置这些策略可以确保重要的消息在被删除之前保留足够长的时间。

通过上述方法的合理配置和使用，Kafka可以在大多数情况下保证消息不会丢失，同时还能平衡系统的性能和资源利用率。然而，完全零丢失的保证可能需要在性能和资源使用上做出一些妥协。

### Kafka 如何保证消息不重复消费？

Kafka 本身提供了一些机制来帮助保证消息不丢失以及减少消息的重复消费，但完全避免重复消费通常需要客户端的配合。以下是一些关键点和建议策略：

#### 保证消息不丢失

1. **副本机制（Replication）**：Kafka 通过副本机制确保消息在集群中的多个节点上有副本，即使某些节点失败，消息也不会丢失。设置合适的副本因子（replication factor）是关键，通常推荐至少设置为3。

2. **持久化**：Kafka 默认将所有消息持久化到磁盘，这也是确保消息不丢失的重要机制。

3. **确认机制（Acknowledgements）**：生产者可以配置`acks`参数来要求broker在确认消息之前必须要有的确认数，`acks=all`意味着leader副本和所有follower副本都确认接收到消息后，消息才被认为是成功写入。

4. **幂等生产者**：启用幂等性配置（`enable.idempotence=true`），可以确保即使因为网络问题导致的生产者重试，消息也不会在Kafka中被重复写入。

#### 避免消息重复消费

主要是对offset位置的处理。

1. **幂等消费**：确保消费者处理消息的逻辑是幂等的，即多次处理相同的消息不会改变系统状态的最终结果。

2. **提交消费偏移（Offset Committing）**：Kafka 消费者通过提交已经成功处理消息的偏移量来跟踪其在分区中的位置。即使发生重启或故障转移，消费者也能从上次提交的偏移量继续消费，减少重复消费的机会。

3. **精确一次处理（Exactly Once Semantics, EOS）**：Kafka 0.11 版本引入了事务性消息，可以通过在生产者和消费者之间开启事务来保证精确一次的处理语义。对于消费者，这意味着即使在重平衡操作中也能避免消息的重复消费。

4. **外部存储消费偏移量**：在某些场景下，消费者可以将消费的偏移量存储在外部系统（如数据库）中，这样即使消费者重启，也能从外部系统中获取到上次消费的位置，避免重复消费。

5. **使用幂等性数据库操作**：确保消费者向数据库写入数据的操作是幂等的，即重复执行相同的操作不会导致数据的不一致。

尽管 Kafka 提供了上述机制来帮助保证消息不丢失和减少重复消费的可能性，但在实际应用中，正确配置和设计消费者的业务逻辑仍然是确保消息处理正确性的关键。

## RabbitMQ

rabbitMq是 producer + broker(exchange -> MQ) + consumer + 4种路由规则(fanout, direct, topic, headers)

### chatgpt给出的示例（推模式）

当然可以。下面是一个使用Java语言和RabbitMQ进行简单消息发送和接收的示例。这个示例分为两个部分：发送者（Producer）和接收者（Consumer）。

在开始之前，请确保你已经安装了RabbitMQ服务器，并且在你的Java项目中引入了RabbitMQ的客户端库。如果你使用的是Maven，你可以在`pom.xml`文件中添加如下依赖：

```xml
<dependency>
    <groupId>com.rabbitmq</groupId>
    <artifactId>amqp-client</artifactId>
    <version>5.9.0</version>
</dependency>
```

请根据你的RabbitMQ服务器设置适当调整以下示例中的连接参数。

#### 发送者（Producer）

```java
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;

public class Send {

  private final static String QUEUE_NAME = "hello";

  public static void main(String[] argv) throws Exception {
    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");
    try (Connection connection = factory.newConnection();
         Channel channel = connection.createChannel()) {
      channel.queueDeclare(QUEUE_NAME, false, false, false, null);
      String message = "Hello World!";
      channel.basicPublish("", QUEUE_NAME, null, message.getBytes());
      System.out.println(" [x] Sent '" + message + "'");
    }
  }
}
```

#### 接收者（Consumer）

```java
import com.rabbitmq.client.*;

public class Recv {

  private final static String QUEUE_NAME = "hello";

  public static void main(String[] argv) throws Exception {
    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");
    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();

    channel.queueDeclare(QUEUE_NAME, false, false, false, null);
    System.out.println(" [*] Waiting for messages. To exit press CTRL+C");

    DeliverCallback deliverCallback = (consumerTag, delivery) -> {
      String message = new String(delivery.getBody(), "UTF-8");
      System.out.println(" [x] Received '" + message + "'");
    };
    channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -> { });
  }
}
```

这个示例涵盖了RabbitMQ最基本的使用场景：一个生产者发送消息到队列，一个消费者从队列中接收消息。在这个例子中，队列名为`hello`。

这个简单的示例是基于RabbitMQ官方教程的，它展示了如何在Java中使用RabbitMQ进行基本的消息发送和接收。你可以在RabbitMQ的官方文档中找到更多高级特性和使用场景的示例。

#### 代码分析

当然，让我们详细解释上面的Java示例代码，它演示了如何使用RabbitMQ进行基本的消息发送和接收。

##### 发送者（Producer）

发送者负责创建消息并将其发送到队列中。在我们的示例中，发送者的代码如下：

```java
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;
```

这段代码首先导入了RabbitMQ客户端库中的必要类。

```java
public class Send {
  private final static String QUEUE_NAME = "hello";
```

定义了一个`Send`类和一个静态字符串`QUEUE_NAME`，用于指定我们想要发送消息到的队列的名称。

```java
public static void main(String[] argv) throws Exception {
    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");
```

在`main`方法中，创建了一个`ConnectionFactory`对象并设置了RabbitMQ服务器的地址。这里我们使用`localhost`，假设RabbitMQ服务器运行在本地。

```java
try (Connection connection = factory.newConnection();
     Channel channel = connection.createChannel()) {
```

使用`ConnectionFactory`创建一个新的连接（`Connection`）到RabbitMQ服务器，并从这个连接中创建一个通道（`Channel`）。这个通道是大多数API操作的出发点。

```java
channel.queueDeclare(QUEUE_NAME, false, false, false, null);
```

通过通道声明一个队列。如果队列不存在，RabbitMQ会自动创建它。`queueDeclare`方法的参数分别是：队列名称、是否持久化（消息是否应该在RabbitMQ重启后仍然存在）、是否独占（队列是否仅由创建它的连接使用）、是否自动删除（队列在最后一个消费者断开时是否自动删除）、其他参数（队列的其他属性）。

```java
String message = "Hello World!";
channel.basicPublish("", QUEUE_NAME, null, message.getBytes());
```

定义要发送的消息，然后使用`basicPublish`方法将消息发布到队列中。`basicPublish`方法的参数是：交换器名称（这里是空字符串，意味着我们使用默认的交换器）、路由键（我们的队列名称）、其他属性（消息的其他属性，这里为null）、消息体（消息内容的字节表示）。

##### 接收者（Consumer）

接收者负责从队列中接收消息。接收者的代码如下：

```java
import com.rabbitmq.client.*;
```

同样地，我们首先导入了RabbitMQ客户端库中的必要类。

```java
public class Recv {
  private final static String QUEUE_NAME = "hello";
```

定义了一个`Recv`类和一个静态字符串`QUEUE_NAME`，用于指定我们想要从中接收消息的队列的名称。

```java
public static void main(String[] argv) throws Exception {
    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");
    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();
```

这部分与发送者类似，创建了一个连接到RabbitMQ服务器的`Connection`和一个`Channel`。

```java
channel.queueDeclare(QUEUE_NAME, false, false, false, null);
```

声明一个队列，以确保它存在。参数与发送者中相同。

```java
System.out.println(" [*] Waiting for messages. To exit press CTRL+C");
```

打印一条消息到控制台，表示消费者正在等待接收消息。

```java
DeliverCallback deliverCallback = (consumerTag, delivery) -> {
    String message = new String(delivery.getBody(), "UTF-8");
    System.out.println(" [x] Received '" + message + "'");
};
channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -> { });
```

定义了一个`DeliverCallback`接口的实现，当接收到消息时，这个回调函数会被调用。它从`delivery`对象中提取消息体并将其打印到控制台。然后，使用`basicConsume`方法来启动消息的消费过程，指定队列名称、是否自动确认消息、`DeliverCallback`实例和取消消

##### 推模式

给出的代码示例使用的是推模式（Push mode）。

在RabbitMQ中，推模式是指消息从队列自动推送到消费者。这种方式下，消费者不需要主动去队列拉取消息，而是通过一个回调机制，当消息到达队列时，RabbitMQ服务器会自动将消息推送给消费者。在示例代码中，这体现在`basicConsume`方法的使用上：

```java
channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -> { });
```

这行代码注册了一个回调函数`deliverCallback`，RabbitMQ会在新消息到达时调用这个回调函数，将消息推送给消费者。这里的`true`参数指的是自动消息确认机制，意味着一旦消息被成功推送，它就会被自动标记为已确认，RabbitMQ会从队列中移除这个消息。

相比之下，拉模式（Pull mode）是指消费者主动向队列请求消息，这通常通过`basicGet`方法实现。在拉模式下，消费者需要定期检查队列中是否有新的消息，并主动地从队列中获取它们。

推模式适用于实时或近实时的消息处理场景，因为它能够确保消息一到达就立即被处理。而拉模式可能更适用于那些处理能够延迟或批量处理消息的应用场景。

### 示例2（拉模式）

使用拉模式（Pull mode）从RabbitMQ接收消息的示例稍微不同，因为在这种模式下，消费者主动从队列获取消息，而不是等待RabbitMQ推送消息。下面是如何用Java实现拉模式的一个简单示例。

#### 拉模式消费者

在这个例子中，我们将使用之前定义的`QUEUE_NAME`（"hello"队列）来从中拉取消息。请确保你已经按照之前的指南设置了RabbitMQ的环境和依赖。

```java
import com.rabbitmq.client.*;

public class PullConsumer {
    private final static String QUEUE_NAME = "hello";

    public static void main(String[] argv) throws Exception {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost("localhost"); // 或者根据你的设置调整RabbitMQ服务器的地址
        try (Connection connection = factory.newConnection();
             Channel channel = connection.createChannel()) {

            channel.queueDeclare(QUEUE_NAME, false, false, false, null);
            System.out.println(" [*] Waiting for messages. To exit press CTRL+C");

            boolean autoAck = false; // 自动确认关闭
            GetResponse response = channel.basicGet(QUEUE_NAME, autoAck);

            if (response != null) {
                AMQP.BasicProperties props = response.getProps();
                byte[] body = response.getBody();
                String message = new String(body, "UTF-8");
                System.out.println(" [x] Received '" + message + "'");

                // 手动发送消息确认
                long deliveryTag = response.getEnvelope().getDeliveryTag();
                channel.basicAck(deliveryTag, false);
            } else {
                System.out.println("No message retrieved");
            }
        }
    }
}
```

在这个例子中，我们首先创建了连接和通道，然后尝试从`hello`队列中获取一条消息。我们使用`basicGet`方法尝试拉取消息，这个方法的第一个参数是队列的名称，第二个参数是是否自动确认消息的标志。

- 如果`autoAck`为`true`，服务器会在发送消息后立即将其标记为已确认状态。
- 如果`autoAck`为`false`，则需要你手动调用`basicAck`来确认消息，这里的`deliveryTag`是服务器传递给消费者的一个唯一标识符，用于确认消息。

这个简单的示例只尝试从队列中获取一条消息。在实际应用中，你可能会在某种循环结构中调用`basicGet`，以持续从队列中拉取消息。需要注意的是，频繁地使用拉模式可能会增加客户端和服务器之间的通信负担，特别是在消息到达率非常低的情况下。因此，根据应用场景选择推模式或拉模式是很重要的。

==在这行代码中：==

```java
GetResponse response = channel.basicGet(QUEUE_NAME, autoAck);
```

- `GetResponse`: 这是RabbitMQ Java客户端库中的一个类，代表从队列中获取的单个消息的响应。`GetResponse`对象包含了消息体、消息的属性和其他一些元数据，比如消息的投递标签（delivery tag）。

- `channel`: 这代表了一个到RabbitMQ服务器的通道。在RabbitMQ中，几乎所有的操作都是通过通道来完成的。通道是建立在连接之上的轻量级连接，用于执行实际的AMQP命令。

- `basicGet`: 这是Channel类的一个方法，用于以拉模式从队列中获取消息。这意味着，客户端代码主动请求从队列中获取下一条消息，而不是通过回调方式等待RabbitMQ推送消息。

- `QUEUE_NAME`: 这是要从中获取消息的队列的名称。在你的示例代码中，这个值被设置为`"hello"`，表示将从名为`hello`的队列中获取消息。

- `autoAck`: 这是一个布尔值，指示是否自动发送ACK（确认）来通知RabbitMQ一条消息已经被接收并且可以从队列中移除。如果设置为`true`，消息在发送给消费者之后会立即从队列中移除，而不管消费者是否真正处理了该消息。如果设置为`false`，消费者需要显式地调用`channel.basicAck`方法来发送ACK，确认消息已被处理，RabbitMQ之后才会从队列中移除它。不发送ACK的话，消息会被RabbitMQ保留在队列中，可能会被重新投递给消费者。

这行代码尝试从指定队列中获取一条消息。如果队列中有待处理的消息，它会作为`GetResponse`对象返回，然后你可以从这个对象中提取出消息内容、属性等信息。如果队列为空，没有消息可以获取，那么`basicGet`方法会返回`null`。这允许你在代码中检查是否实际获取到了消息，并据此做出适当的处理。

### pub/sub模式和topic模式的区别

RabbitMQ是一个广泛使用的开源消息代理和队列服务器。在RabbitMQ中，发布/订阅(pub/sub)模式和主题(topic)模式是两种不同的消息分发机制，它们在消息路由和过滤方面有一些关键区别：

1. **发布/订阅(pub/sub)模式**：
   - 在发布/订阅模式中，消息被发送到一个交换机（exchange），而不是直接发送到队列。然后，交换机将消息广播到所有绑定到它的队列中，无论队列的路由键是什么。
   - 发布者(publisher)发布消息而不需要知道哪些订阅者(subscriber)或队列会接收这些消息。
   - 这种模式适合于广播通知或消息，其中消息需要被所有感兴趣的订阅者处理。

2. **主题(topic)模式**：
   - 主题模式是发布/订阅模式的一个变种，它增加了基于路由键（routing key）和模式匹配的灵活性。交换机将根据发送的消息的路由键和队列绑定时指定的模式来决定是否路由消息到该队列。
   - 路由键通常是一个有点（`.`）分隔的字符串，用于指定消息的某种层次结构或分类。例如，`"stock.us.nasdaq"` 和 `"weather.europe.london"`。
   - 队列可以通过指定匹配模式来绑定到交换机，如 `*` 匹配一个单词，`#` 匹配零个或多个单词。例如，一个队列可以通过 `"stock.us.*"` 来接收所有关于美国股市的消息，而另一个队列可以通过 `"weather.europe.#"` 来接收所有关于欧洲天气的消息。
   - 这种模式适合于消息的精确路由，比如将消息只发送给确切关心该特定主题的订阅者。

简而言之，发布/订阅模式是一种更基本的消息广播机制，适用于所有订阅者都需要接收所有消息的场景。而主题模式提供了更高的灵活性和精确控制，允许根据消息的路由键和队列的绑定模式来有选择性地分发消息。

### 如何保证消息的可靠性

在RabbitMQ中，确保消息从生产者到RabbitMQ服务器的过程中的可靠性是非常重要的。这里主要涉及到两种机制：事务机制和Confirm机制。这两种机制都旨在保证消息能够安全、可靠地传递到RabbitMQ服务器，但它们在实现方式和性能影响上有所不同。

#### 事务机制

事务机制提供了一种方式，通过它生产者可以将多个动作（例如，发送消息）包裹在一个事务中。这些动作要么全部成功，要么全部失败，这提供了很高的可靠性保证。

- **开始事务**：生产者开始一个事务。
- **发送消息**：生产者在事务中发送一个或多个消息。
- **提交事务**：如果所有消息都被成功发送到RabbitMQ，生产者提交事务，此时RabbitMQ会将这些消息标记为可用，之后消息可以被队列接收。
- **回滚事务**：如果在发送消息过程中出现错误，生产者可以回滚事务，这样就好像之前在事务中发送的消息从未发生过。

事务机制的优点在于它提供了很强的一致性保证。但缺点是，事务机制在RabbitMQ中的实现会显著降低消息吞吐量，因为每次事务提交都需要磁盘I/O操作，这是一个相对较慢的过程。

#### Confirm机制（Publisher Confirms）

Confirm机制是另一种保证消息可靠性的方法，相比事务机制，它提供了更高的性能。Confirm机制允许生产者知道其消息是否已经被RabbitMQ服务器成功接收。

- **启用Confirm模式**：生产者将频道设置为confirm模式。
- **发送消息**：生产者发送消息。
- **等待确认**：每当消息被成功接收，RabbitMQ会发送一个确认（ack）给生产者。如果消息无法被RabbitMQ接收，将会发送一个nack消息。

Confirm机制可以是同步的，也可以是异步的。异步Confirm模式提供了更好的性能，因为生产者不需要在每条消息发送后立即等待确认，而是可以继续发送其他消息，同时异步监听确认。

#### 比较和选择

- **性能**：Confirm机制通常比事务机制提供更好的性能。事务机制由于需要磁盘I/O操作，会导致较大的性能开销。
- **可靠性**：两者都提供了消息可靠性保证，但通过不同的方式。事务机制适用于需要非常强一致性保证的场景，而Confirm机制适用于大多数需要高性能和高可靠性的场景。

在实际应用中，推荐优先考虑使用Confirm机制，因为它在确保消息可靠性的同时，提供了更好的性能。如果确实需要事务性的保证，比如在发送消息的过程中需要执行多个操作，并且这些操作需要作为一个整体来成功或失败，那么可以选择使用事务机制。

### 保证消息队列的高可用

RabbitMQ支持多种集群模式，以满足不同的可用性和性能需求。其中两种常见的集群配置是普通集群模式和镜像集群模式：

#### 普通集群模式（Regular Cluster）

消息数据只在自己的队列实例上存储，不会往所有队列里同步数据。但是配置信息会在所有节点中同步。

- **目的**：提高吞吐量和容错性。
- **工作原理**：在普通集群模式下，所有的RabbitMQ节点都是平等的，消息队列的元数据（如队列的存在，交换机的存在等）在集群中的所有节点上同步，但消息内容只存在于消息进入集群时所连接的那个节点上。
- **消息复制**：消息本身不会在节点间自动复制。如果一个节点宕机，那么存储在该节点上的消息会不可用，直到节点恢复。
- **使用场景**：适用于消息传递性能比消息可用性更重要的场景。它可以通过增加更多的节点来提高处理能力，但需要额外的策略来处理节点故障时的消息可用性问题。

#### 镜像集群模式（Mirrored Queue）

- **目的**：提高队列的可用性和容错性。
- **工作原理**：镜像集群模式通过在多个节点上创建队列和消息的镜像来提高队列的容错性。当在镜像队列模式下创建队列时，队列的所有操作（如消息的发布、消息的确认等）都会在几个节点上镜像执行，确保队列的状态在这些节点上保持一致。
- **消息复制**：这意味着消息会被复制到多个节点，如果主节点（即持有队列主副本的节点）宕机，其中一个镜像节点会自动接管，成为新的主节点，从而保证队列的持续可用性。
- **使用场景**：适用于队列数据安全和可用性非常重要的场景。虽然它提高了队列的可用性，但是由于消息在多个节点间的复制，可能会增加网络带宽的需求和降低消息吞吐量。

#### 对比

- **性能**：普通集群模式通常性能更高，因为它不需要在节点间复制消息。镜像集群模式因为涉及到跨节点的消息复制，可能会有更高的延迟和更低的吞吐量。
- **可用性**：镜像集群模式提供了更高的可用性，因为它能够在主节点故障时自动切换到镜像节点，而普通集群模式在节点宕机时，该节点上的队列和消息会不可用，直到节点恢复。
- **场景适用性**：普通集群模式适合于追求高性能、可以容忍某个节点故障时部分消息不可用的场景。镜像集群模式适用于需要保证消息不丢失、队列高可用的场景，尤其是在处理重要数据时。

在选择集群模式时，需要根据应用场景的具体需求，在性能和可用性之间做出权衡。

### RabbitMQ的工作模式

RabbitMQ 是一个灵活的消息代理，支持多种工作模式以适应不同的消息处理需求。下面是RabbitMQ的一些核心工作模式：

#### 1. 简单队列（Simple Queue）

- **基本模式**：一对一的消息传递模式。一个生产者发送消息到队列，一个消费者从队列接收消息。
- **适用场景**：简单的任务分发，适用于任务不需要被多个消费者共享的场景。

#### 2. 工作队列（Work Queues）

主要用来分布式调度任务，和xxl-job的思想类似。在用xxl-job实现任务调度的时候，可以去扫mysql中的待做任务列表。工作队列直接把消息队列中的数据分发给消费者。

- **目的**：分布式的任务处理系统，用于在多个工作者（消费者）之间分配任务。
- **适用场景**：当有一系列的任务需要被处理，但处理每个任务都需要一些时间时，可以使用工作队列来并行处理这些任务。

#### 3. 发布/订阅（Publish/Subscribe）

- **模式**：一个生产者将消息发送到交换机，而不是直接发送到队列。交换机将消息发送给多个队列，实现一对多的消息分发。
- **适用场景**：适用于消息需要被多个消费者同时获取的场景，例如日志系统。

#### 4. 路由（Routing）

- **模式**：生产者将消息发送到交换机，并指定一个路由键。交换机根据路由键决定将消息路由到哪个队列。
- **适用场景**：当消息只需要发送给一部分消费者时。例如，基于消息的严重性级别（如error、info）进行路由。

#### 5. 主题（Topics）

- **模式**：消息发送到交换机时带有路由键。这个路由键是一个可以携带多级别（用点`.`分隔）的标识符。交换机根据这个路由键将消息路由到一个或多个队列，队列绑定时可以使用通配符（`*`代表一个词，`#`代表零个或多个词）来匹配路由键。
- **适用场景**：适用于更复杂的路由模式，允许实现更灵活的消息分发策略。

#### 6. 头交换（Headers Exchange）

- **模式**：消息基于消息头而不是路由键进行路由。生产者和队列之间的匹配不是通过路由键，而是通过消息头的键值对。
- **适用场景**：适用于路由决策需要基于多个属性进行的高级场景。

#### 7. RPC（Remote Procedure Call）

- **模式**：在RabbitMQ中实现RPC允许一个客户端发送请求消息，服务端响应结果消息。
- **适用场景**：适用于需要请求/响应模式的分布式系统，例如客户端需要从服务端请求数据。

每种工作模式都适用于不同的场景，根据具体需求选择最合适的模式非常重要。RabbitMQ的灵活性和多样性使其成为处理各种消息传递需求的强大工具。

#### 工作队列模式详解

工作队列（Work Queues），也称为任务队列（Task Queues），是RabbitMQ中用来分布式任务处理和负载均衡的一种模式。在这种模式下，任务不是由单个消费者来处理，而是分散到多个工作者（消费者）之间进行处理。这样可以避免对单个工作节点的过载，并且可以通过增加更多的工作者来提高处理能力。

##### 工作原理

1. **生产者（Producer）**：生产者负责创建任务。任务以消息的形式发送到队列中。
2. **队列（Queue）**：任务存储在队列中，等待被消费者处理。RabbitMQ中的队列可以容纳大量的消息，直到它们被消费。
3. **消费者（Consumer）/工作者（Worker）**：消费者从队列中获取任务进行处理。在工作队列模式中，可以有多个消费者同时从同一个队列中取得并处理消息，从而实现任务的负载均衡。

##### 使用场景

工作队列模式适合于需要处理大量独立任务的应用，这些任务需要进行背景处理，例如：

- 批量图像处理或视频编码。
- 发送大量电子邮件。
- 批处理计算密集型任务。

##### 特性

- **负载均衡**：RabbitMQ会自动尝试将队列中的任务平均分配给所有的消费者。
- **持久化**：可以将任务（消息）设置为持久化，确保即使RabbitMQ重启，任务也不会丢失。
- **手动消息确认**：消费者处理完成任务后，需要手动发送一个确认（acknowledgement）给RabbitMQ，这样RabbitMQ才会将该任务从队列中移除。这确保了即使消费者因故障停止，任务也不会丢失，可以由其他消费者接手处理。
- **公平调度（Fair Dispatch）**：通过设置预取计数（prefetch count），可以控制RabbitMQ给每个消费者分配任务的数量，避免某些消费者因为处理较慢的任务而积压过多任务。

##### 实现步骤

1. **定义队列**：生产者声明一个队列，用于存储待处理的任务。
2. **发送消息**：生产者将任务作为消息发送到队列中。
3. **处理消息**：消费者从队列中接收消息并进行处理。处理完成后，消费者向RabbitMQ发送一个ack，表示任务已成功处理。
4. **消息确认**：一旦RabbitMQ接收到ack，它就会从队列中删除该消息，确保任务不会被重复处理。

##### 注意事项

- **处理时间不一致**：如果任务的处理时间差异很大，建议使用公平调度，避免快速处理的消费者空闲，而处理慢的消费者积压任务。
- **持久化**：为了防止RabbitMQ服务器重启导致的任务丢失，需要将队列、消息设置为持久化。
- **异常处理**：消费者处理任务时可能会遇到异常，需要合理处理这些异常，确保系统的稳定运行。

工作队列模式是一种简单而强大的方法，用于在多个工作者之间分配任务，实现负载均衡和提高系统的处理能力。

## RocketMQ

producer group + broker(topic + queues)  + consumer group + naming server

![img](./pic/16ef386fa3be1e53.jpg)



