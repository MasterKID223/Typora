## Kafka

### 基本概念

Kafka的基本概念：Broker、Topic、Partition、副本Replication、副本类型Leader/Follower。Zookeeper的作用。

- 可以用数据库分库分表的逻辑理解上面的概念。当查询/写入请求并发太大时，一台机器的网络IO和CPU处理不过来，这时要多加机器，把请求分发到不同的机子上，避免太多请求把数据库打挂（数据分库），在Kafka上就是创建多个Broker分流Producer的写入请求和Consumer的查询请求。

- Kafka是发布-订阅模式，分布式消息系统的常用架构，如果有了解机器人的ROS系统，那么这个就比较好理解。依然类比数据库的概念，所有数据写入一张表（Topic），表太大时需要分表，在Kafka中就是创建多个Partition，把一个Topic中的数据均匀的分散到每个Partition上。但是，注意：一个Broker上的某一Topic只能有一个对应的Partition（仅指Leader写入，和副本管理区别开），这点和数据库中的概念不一样。

- 副本Replication指的是Partition的备份，别因为Broker宕机数据丢了。每个Partition的副本数量可以自己设置，但不超过Broker的数量。Patition的Leader副本（只有Leader能写入）和Follower副本不在一个Broker上，要不然Broker宕机副本也丢了。

- Zookeeper帮助Kafka实现Broker的主从架构。在Kafka集群中，要选定一个Broker当主节点（Controller节点），这里涉及到Controller选举算法（八股）。

- 主Broker的作用是：①发挥主从架构中的Master节点的作用，监听Broker的增减；②管理Topic，新增/更新/删除Topic；②管理Partition，分区重新分配（负载均衡）；③副本管理，通知副本同步情况、副本的Leader选举、副本分布在哪个Broker上。

### 默认副本分配策略

Apache Kafka 使用一种称为“范围分区副本分配策略”（Range Partition Replication Strategy）作为其默认的副本分配策略。这种策略确保了数据的均衡分布以及副本在不同节点之间的分散。

当一个主题（Topic）被创建时，每个分区（Partition）的主副本（Leader Replica）和从副本（Follower Replica）都会按照一定的规则分布在不同的broker上。Kafka 采用以下步骤来分配副本：

1. **第一个副本**（通常是主副本Leader）被放置在一个随机选择的broker上。
2. **第二个副本**被放置在与第一个副本不同的broker上，并且这个broker是集群中剩余broker中ID最小的那个。
3. **第三个副本**被放置在剩余broker中ID最小的那个，以此类推，直到达到所需的副本因子（Replication Factor）。

例如，如果一个主题有三个分区，每个分区需要两个副本，并且集群中有三个broker，则副本将按如下方式分布：

- 分区0: 第一个副本位于Broker A，第二个副本位于Broker B。
- 分区1: 第一个副本位于Broker B，第二个副本位于Broker C。
- 分区2: 第一个副本位于Broker C，第二个副本位于Broker A。

这样可以确保即使某个broker失败，数据仍然可用，并且负载可以在所有broker之间均匀分布。如果需要更改副本分配策略，可以通过配置或使用管理工具进行调整。

### 生产者分区器

- 自己指定分区号，但是kafka不做校验

- 重写分区器里的获取分区号的方法

- 有消息Key时，对Key采用默认的murmur2算法，算key的hash值，然后对分区总数取模得到分区号

- 否则不知道发送到哪个分区（未知分区）

  <img src="./pic/image-20240804180556346.png" alt="image-20240804180556346" style="zoom: 67%;" />

### 生产者-Sender发送线程

Sender线程读取数据收集器（主线程放到这里的）中的数据发送：

<img src="./pic/image-20240804205010103.png" alt="image-20240804205010103" style="zoom:67%;" />

不按照Topic-Partition的方式直接发送，考虑到网络传输效率问题，把在同一个Broker上的不同Topic的所有消息包装成一个批次统一发送。

<img src="./pic/image-20240804181113479.png" alt="image-20240804181113479" style="zoom: 67%;" />

### 生产者确定数据正确发送

异步发送：不管sender线程发送是否成功，只要数据收集器中有数据，就连续发送。（2.4.3.3异步发送）

同步发送：sender成功发送的kafka中，并且收到响应后再继续发送。（2.4.3.4同步发送）

### ACKS数据接收应答机制（消息可靠性）

2.4.5 消息可靠性

- ack = 0，sender发送到network client就响应，不保证数据被写入到Broker
- ack = 1，写入到leader副本响应，不保证Broker宕机数据可靠性
- ack = -1，待同步的副本（ISR列表中的同步副本列表）全部同步完成后响应，保证数据可靠性

数据吞吐量随着下降。

### 数据重复和乱序的原因和原理

2.4.6 消息去重 & 有序

幂等性操作的要求：ack=1、开启重试机制、在途请求缓冲区的数据不能超过5。

幂等性只能对同一个分区起作用。

Broker里有一个保存生产者生产数据的分区状态，里面保存了5条数据，每次来数据都会比较新数据和生产者状态区中的5条信息做比对，重复或者顺序不对就重发。

<img src="./pic/image-20240804231557531.png" alt="image-20240804231557531" style="zoom:67%;" />

一条record由（生产者id-数据-序列号）确定，但是当生产者重启后，生产者id会发生变化，此时都是同一条数据但是生产者id不同，仍然会出现消息重复。Kafka无法保证跨分区的幂等，但可以通过事务实现多会话的幂等（同一个生产者重启）。

### 幂等操作-数据事务

生产者在生产数据时，设置一个生产者id，那么通过事务操作，生产者每次重启，自动生成的id是保持不边的。

分布式事务，采用两阶段提交的模式：①Producer向Broker的事务协调器提交事务（预提交）；②事务协调器向Leader副本发送数据marker，通知Broker数据已提交（已提交）。

只保证数据的最终一致性，不保证数据的中间一致性。

### 主题名校验

Producer向Kafka Broker发送数据时，是必须指定主题Topic的，但是这个主题的名称不能是kafka的内部主题名称。Kafka为了管理的需要，创建了2个内部主题，一个是用于事务处理的\_\_transaction_state内部主题，还有一个是用于处理消费者偏移量的\_\_consumer_offsets内部主题。生产者是无法对这两个主题生产数据的，所以在存储数据之前，需要对主题名称进行校验有效性校验。

### 日志文件滚动判断

两个参数：log.segment.bytes和log.roll.hours

### 副本同步

Follower副本主动向Leader副本拉取数据同步。

### 数据同步一致性问题

水位线watermark的概念：是一个虚拟的偏移量，水位线以下的消费者才能看到（所有副本中数据最少的），此时即使Leader挂掉，水位线不变，消费者看到的数据也不会变。

但是当Leader重新选举后，新Leader中的数据只有1,2,3那么，采取截断操作，水位线上的数据不要了。

<img src="./pic/image-20240805160216678.png" alt="image-20240805160216678" style="zoom:67%;" />



### 数据消费的偏移量

消费者（消费者组）在消费完消息之后，会把当前的消费完成的Offset记录以下，下次重启时直接从上一次消费完的位置继续消费，而不从配置中重新获取offset。

### 偏移量同步提交和异步提交

偏移量是每5s自动提交一次，当第4s的时候消费者重启，此时offset还没有提交，那么就会重复消费。

手动保存偏移量：同步提交（提交成功才消费下一条数据）、异步提交。

### 消费者事务

借助其他工具实现kafka的事务。消息获取到，并且消息被正确消费之后才提交偏移量，这个过程用事务包装，防止消息漏消费的情况（刚拿到消息消费者就重启）。

### 事务隔离级别

1. 已提交读，消费者读取已经提交事务成功（生产者）的数据（默认）

2. 未提交读，读取已经提交事务成功和未提交事务成功的数据

### 消费者组

消费者加入消费者组由消费者组调度器（协调）（Group Coordinator）管理。

消费者在消费时，必须处在一个消费者组里，按组消费数据。

同一个消费者组的消费者都订阅同一个主题

![image-20240805212954305](./pic/image-20240805212954305.png)

### 消费者分配策略

==2.6.3.3消费者分配策略Assignor==

Kafka消费者默认的分区分配就是RangeAssignor（范围分区策略），CooperativeStickyAssignor（优化后的粘性分配策略）

### 消费者Leader选举

在 Apache Kafka 中，消费者组（consumer group）中的消费者实例之间会选举一个“Leader”消费者。这个“Leader”消费者的主要职责是协调组内成员之间的分区分配，并代表整个组与 Kafka 集群通信。虽然“Leader”这个概念在消费者组中存在，但它的作用与生产者或 broker 中的 Leader 有所不同。

#### 消费者组 Leader 选举的流程如下：

1. **初始化阶段**：
   - 当消费者首次启动并加入一个消费者组时，它会向 Kafka 集群中的 Group Coordinator 发送一个 `JoinGroupRequest` 请求。
   - Group Coordinator 负责管理消费者组的状态，并协调组内的分区分配。

2. **选举 Leader**：
   - 当 Group Coordinator 收到 `JoinGroupRequest` 后，它会根据组内成员状态执行以下操作：
     - 如果组内没有现有的 Leader，则 Group Coordinator 会选举第一个加入组的消费者作为 Leader。
     - 如果现有的 Leader 离开组（例如，因为应用程序崩溃或重启），Group Coordinator 将选择下一个消费者作为新的 Leader。
   - 选举过程非常简单：Group Coordinator 通常会==选择成员列表中的第一个成员作为 Leader==。这是因为成员列表是按照它们加入组的顺序排序的，所以第一个成员就是第一个加入的消费者。

3. **分配分区**：
   - 一旦选举出 Leader，Leader 将负责为组内所有成员分配分区（Partition）。
   - Leader 会根据消费者组的配置和可用的分区数来制定一个分配方案。
   - 分配方案确定后，Leader 会向 Group Coordinator 发送一个 `SyncGroupRequest` 请求，其中包含分配方案。

4. **同步组状态**：
   - Group Coordinator 收到 `SyncGroupRequest` 后，会将分配方案发送给组内的所有消费者。
   - 消费者收到分配方案后，开始消费分配给它们的分区。

5. **心跳和再平衡**：
   - 消费者会定期向 Group Coordinator 发送心跳信息，表明它们仍在活动。
   - 如果 Group Coordinator 在一定时间内没有接收到某个消费者的任何心跳信息，则认为该消费者已离开组，并触发再平衡过程。
   - 再平衡过程中，Group Coordinator 会重新选举 Leader，并重新分配分区。

#### 关于消费者组 Leader 选举的几个关键点：

- **选举过程简单**：选举过程非常简单，通常选择第一个加入组的消费者作为 Leader。
- **Leader 职责**：Leader 主要负责协调分区分配，并不代表它可以优先消费数据或有其他特殊权限。
- **再平衡**：当消费者加入或离开组时，会发生再平衡，此时 Group Coordinator 会重新选举 Leader 并重新分配分区。
- **非强制性**：消费者组不一定需要 Leader，但在 Kafka 0.10 版本及以后，为了更好地支持再平衡，引入了 Leader 的概念。

请注意，消费者组的 Leader 选举与 Kafka 集群中分区的 Leader 选举不同。后者是指在 Kafka 集群内部，当一个分区的 Leader 副本失效时，集群会选举一个新的 Leader 来继续服务。消费者组的 Leader 选举是为了协调组内成员之间的通信和分区分配。



### Kafka集群脑裂

通过epoch参数，保证最新的Controller为新的集群Controller。
